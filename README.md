# Intelligent Control of the Inverted Pendulum using Classical Reinforcement Learning Algorithms

## Table of Contents
- [English Version](#english-version)
- [Versión en Español](#versión-en-español)

---

<a name="english-version"></a>
## English Version

### Project Overview
This project demonstrates the control of an inverted pendulum using **Q-learning**, a classical reinforcement learning algorithm. By leveraging **Python** and **Pygame**, we developed an interactive simulation to visualize the agent's learning process. The primary goal is to stabilize the pendulum by designing an effective reward function and fine-tuning the learning parameters to achieve faster convergence.

Key features include:
- **Simulation Visualization**: A dynamic graphical interface to observe the agent's learning in real time.
- **Performance Analysis**: Graphs and metrics illustrating the agent's policy convergence and learning efficiency.
- **Customizability**: Adjustable parameters to experiment with different reward structures and learning configurations.

This implementation highlights the practical applications of Q-learning in addressing complex control problems. The code is modular, well-documented, and beginner-friendly, making it accessible for both students and professionals.

### How to Get Started
For a detailed guide on:
1. Setting up the environment.
2. Running the simulation.
3. Modifying parameters.
4. Interpreting results.

Visit the comprehensive README here: [Readme](https://github.com/MaxSaavedraLux666/Intelligent-Control-of-the-Inverted-Pendulum/blob/dev_max/Developer/simulation/Readme.md)

---

<a name="versión-en-español"></a>
## Versión en Español

### Descripción del Proyecto
Este proyecto ilustra el control de un péndulo invertido mediante el uso de **Q-learning**, un algoritmo clásico de aprendizaje por refuerzo. Utilizando **Python** y **Pygame**, desarrollamos una simulación interactiva para visualizar el proceso de aprendizaje del agente. El objetivo principal es estabilizar el péndulo diseñando una función de recompensa eficiente y ajustando los parámetros de aprendizaje para lograr una convergencia más rápida.

Características clave:
- **Visualización de la Simulación**: Una interfaz gráfica dinámica para observar el aprendizaje del agente en tiempo real.
- **Análisis de Rendimiento**: Gráficos y métricas que muestran la convergencia de la política del agente y la eficiencia del aprendizaje.
- **Personalización**: Parámetros ajustables para experimentar con diferentes estructuras de recompensas y configuraciones de aprendizaje.

Esta implementación resalta las aplicaciones prácticas de Q-learning para resolver problemas complejos de control. El código es modular, bien documentado y fácil de entender, ideal para estudiantes y profesionales.

### Cómo Comenzar
Para una guía detallada sobre:
1. Configuración del entorno.
2. Ejecución de la simulación.
3. Modificación de parámetros.
4. Interpretación de resultados.

Visite el README completo aquí: [Readme](https://github.com/MaxSaavedraLux666/Intelligent-Control-of-the-Inverted-Pendulum/blob/dev_max/Developer/simulation/Readme.md)
